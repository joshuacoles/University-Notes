[[next](MA10210se5.html)] [[prev](MA10210se3.html)] [[prev-tail](MA10210se3.html#tailMA10210se3.html)] [[tail](#tailMA10210se4.html)] [[up](MA10210ch1.html#MA10210se4.html)]

### 1.4 [The null space of a matrix](MA10210.html#QQ2-7-10)

Definition 1.  
A subset $V\subseteq\left(ùîΩ\right)^{n}$ is a linear subspace if

(i)

$0\in V$ (so $V$ is non-empty)

(ii)

$\forall v,w\in V$ , $\lambda,\mu\inùîΩ$

$$
\lambda v + \mu w \in V .
$$

Note.  
This immediately implies that if $v_{1},\dots ,v_{k}\in V$ and $\left(\lambda\right)_{1},\dots ,\left(\lambda\right)_{k}\inùîΩ$ , then

$$
\sum_{i = 1}^{k} \left(\lambda\right)_{i} v_{i} \in V
$$

Geometric examples:

*   lines through $0$ in $‚Ñù^{2}$
*   lines and planes through $0$ in $‚Ñù^{3}$ .

Definition 2.  
For a matrix $A\in M_{m , n}\left( ùîΩ \right)$ , the null space is

$$
N_{A} = \left\{ x \in \left(ùîΩ\right)^{n} : A x = 0 \right\} ,
$$

i.e. the set of solutions to the homogeneous system.

Proposition 3.  
$N_{A}$ is a linear subspace of $\left(ùîΩ\right)^{n}$ .

Proof.

(i)

$A0=0$ , so $0\in N_{A}$ .

(ii)

For $v,w\in N_{A}$ , $\lambda,\mu\inùîΩ$ , 
$$
\begin{align}
A\left( \lambda v + \mu w \right) & = & \lambda Av+\mu Aw & \text{} \\ & = & \lambda 0+\mu 0 & \text{} \\ & = & 0, & \text{}
\end{align}
$$

so $\lambda v+\mu w\in N_{A}$ , as required. ‚ñ°

Definition 4.  
A basis of a linear subspace $V\subseteq\left(ùîΩ\right)^{n}$ is a list $\beta$ of vectors $w_{1},\dots ,w_{k}\in V$ such that every $v\in V$ can be written as a unique linear combination

$$
v = \sum_{i = 1}^{k} \left(\lambda\right)_{i} w_{i}
$$

with $\left(\lambda\right)_{i}\inùîΩ$ .

Example 5.  
Consider the list $e_{1},\dots ,e_{n}\in\left(ùîΩ\right)^{n}$ of ‚Äúelementary vectors‚Äù $e_{k}=\left(col\right)_{k}\left( I \right)$ . Then any $x=\left( x_{1} , \dots  , x_{n} \right)\in\left(ùîΩ\right)^{n}$ can be written as a linear combination

$$
x = \sum_{i = 1}^{n} \left(\lambda\right)_{i} e_{i}
$$

in a unique way, namely with $\left(\lambda\right)_{i}=x_{i}$ . Thus $e_{1},\dots ,e_{n}$ is a basis for $\left(ùîΩ\right)^{n}$ , and it is called the standard basis.

For any matrix $A$ , we can find a basis of $N_{A}$ using Gaussian elimination.

Example 6.  
Find a basis for the following matrix $A$ .

$$
\begin{align}
 & & A=\begin{pmatrix} \begin{matrix}1 & 2 & 0 & 1 \\ 2 & 5 & 1 & 4\end{matrix} \end{pmatrix} & \text{} \\ & \rightarrow _{}^{R_{2} - 2 R_{1}} & \begin{pmatrix} \begin{matrix}1 & 2 & 0 & 1 \\ 0 & 1 & 1 & 2\end{matrix} \end{pmatrix} & \text{} \\ & \rightarrow _{}^{R_{1} - 2 R_{2}} & \begin{pmatrix} \begin{matrix}1 & 0 & -2 & -3 \\ 0 & 1 & 1 & 2\end{matrix} \end{pmatrix}\text{RREF} & \text{}
\end{align}
$$

General solution of $Ax=0$ is given by assigning arbitrary values

$$
x_{4} = \mu , x_{3} = \lambda
$$

to the two non-pivot variables, and then solving for the pivot variables

$$
\begin{align}
x_{2}+x_{3}+2x_{4}=0 & \Rightarrow & x_{2}=-\lambda-2\mu & \text{} \\ x_{1}-2x_{3}-3x_{4}=0 & \Rightarrow & x_{1}=2\lambda+3\mu, & \text{}
\end{align}
$$

i.e.

$$
x = \begin{pmatrix} 2\lambda+3\mu \\ -\lambda-2\mu \\ \lambda \\ \mu \end{pmatrix} = \lambda \begin{pmatrix} 2 \\ -1 \\ 1 \\ 0 \end{pmatrix} + \mu \begin{pmatrix} 3 \\ -2 \\ 0 \\ 1 \end{pmatrix} .
$$

Since $\lambda,\mu$ are uniquely determined by $x$ , we see that

$$
w_{1} = \begin{pmatrix} 2 \\ -1 \\ 1 \\ 0 \end{pmatrix} , w_{2} = \begin{pmatrix} 3 \\ -2 \\ 0 \\ 1 \end{pmatrix}
$$

is a basis of $N_{A}$ .

We can interpret the Fundamental Lemma [1.2.6](MA10210se2.html#x5-6001r6) in terms of the null space $N_{A}$ as follows.

Lemma 7.  
Let $A$ be an $m\times n$ matrix. If $N_{A}=\left\{ 0 \right\}$, then $n\leq m$ .

Proof. By the Fundamental Lemma [1.2.6](MA10210se2.html#x5-6001r6), if $n>m$ , the homogeneous linear system $Ax=0$ has a nonzero solutions, i.e. $N_{A}\neq\left\{ 0 \right\}$. So if $N_{A}=\left\{ 0 \right\}$, $n$ can not be bigger than $m$ , i.e. $n\leq m$ . ‚ñ°

#### [Consequence of linearity for $Ax=b$ : general solution revisit](MA10210li1.html#QQ2-7-11)

Suppose a linear system $Ax=b$ has at least one ‚Äòparticular solution‚Äô $x=v$ . Then for the general solution

$$
\begin{align}
 & & Ax=b & \text{} \\ & \Rightarrow & A\left( x - v \right)=Ax-Av=b-b=0. & \text{}
\end{align}
$$

Thus,

$$
\left\{x : A x = b\right\} = v + \left\{x^{‚Ä≤} : A x^{‚Ä≤} = 0\right\} = v + N_{A} .
$$

That is, the general solution of the inhomogeneous system $Ax=b$ is given by

$$
\text{a particular solution } v + \text{ the general solution of the homogeneous system } A x = 0 .
$$

(Using terminology from Algebra 1A, this says that the solution set $\left\{x : A x = b\right\}$ is a coset of $N_{A}$ .) So, if $w_{1},\dots ,w_{k}$ is a basis of $N_{A}$ , then the general solution of $Ax=b$ is

$$
x = v + \left(\lambda\right)_{1} w_{1} + \dots  + \left(\lambda\right)_{k} w_{k} .
$$

![No alt text was set.](diagrams/fig01d.svg)

#### [Dimension and rank](MA10210li1.html#QQ2-7-12)

Given a linear subspace $V\leq\left(ùîΩ\right)^{n}$ , there can be many different bases for $V$ . However, the number of elements in a basis will turn out to depend only on $V$ , to be proved in Chapter 3. This number is called the ‚Äúdimension‚Äù of $V$ .

In the case of the null space $N_{A}$ of $A\in M_{m , n}\left( A \right)$ , the dimension of $N_{A}$ is the number of free parameters in the general solution of $Ax=0$ . When we solve by Gaussian elimination, this corresponds to the number of non-pivot columns in a REF reduction of $A$ . In Chapter 3 we will prove that the number of pivots is independent of how we reduce $A$ to REF. This leads to the following definition.

Definition 8.  
The rank of a matrix $A\in M_{n , m}\left( ùîΩ \right)$ is the number of pivots (non-zero rows) when $A$ is converted to REF (or RREF).

[[next](MA10210se5.html)] [[prev](MA10210se3.html)] [[prev-tail](MA10210se3.html#tailMA10210se3.html)] [[front](MA10210se4.html)] [[up](MA10210ch1.html#MA10210se4.html)]