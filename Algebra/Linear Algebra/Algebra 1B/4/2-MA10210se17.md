[[next](MA10210se18.html)] [[prev](MA10210se16.html)] [[prev-tail](MA10210se16.html#tailMA10210se16.html)] [[tail](#tailMA10210se17.html)] [[up](MA10210ch4.html#MA10210se17.html)]

### 4.2 [Properties of $ \det $](MA10210.html#QQ2-23-36)

Proposition 1.  
Considering a matrix $A\in M_{n , n}\left( \F \right)$ as a list of (column) vectors $c_{1},\dots ,c_{n}\in\left(\F\right)^{n}$ , the function $ \det A= \det \left( c_{1} , \dots  , c_{n} \right)$ is

a.

Multilinear: if for any one $j=1,\dots ,n$ ,

$$
c_{j} = \lambda v + \mu w , \lambda , \mu \in \F , v , w \in \left(\F\right)^{n}
$$

then

$$
\begin{align}
 \det \left( c_{1} , \dots  , c_{j} , \dots  , c_{n} \right) & = & \lambda \det \left( c_{1} , \dots  v , \dots  , c_{n} \right)+\mu \det \left( c_{1} , \dots  w , \dots  , c_{n} \right). & \text{}
\end{align}
$$

b.

Alternating: If $c_{i}=c_{j}$ for some $i\neq j$ , then

$$
 \det  \left( c_{1} , \dots  , c_{n} \right) = 0 .
$$

Note.  
Since $ \det A^{T}= \det A$ , these two properties also hold when viewing $ \det A$ as a function of the rows.

Proof.

a.

Write

$$
a_{i j} = \lambda v_{i} + \mu w_{i} .
$$

Each summand has precisely one factor in each column:

$$
\begin{align}
a_{\sigma \left( 1 \right) 1}\dots a_{\sigma \left( j \right) j}\dots a_{\sigma \left( n \right) n} & = & \lambda a_{\sigma \left( 1 \right) 1}\dots v_{\sigma \left( j \right)}\dots a_{\sigma \left( n \right) n} & \text{} \\ & & +\mu a_{\sigma \left( 1 \right) 1}\dots w_{\sigma \left( j \right)}\dots a_{\sigma \left( n \right) n}. & \text{}
\end{align}
$$

Adding such terms gives the result.

b.

Consider the coset partition 
$$
\begin{align}
S_{n}=A_{n} & \cup & A_{n}\left( i j \right),\text{where }A_{n}=\text{alternating group} & \text{} \\ \text{even} & & \text{odd} & \text{}
\end{align}
$$

Then

$$
 \det  A = \underset{\sigma \in A_{n}}{\sum} a_{\sigma \left( 1 \right) 1} \dots  a_{\sigma \left( n \right) n} - \underset{\tau \in A_{n} \left( i j \right)}{\sum} a_{\tau \left( 1 \right) 1} \dots  a_{\tau \left( n \right) n}
$$

Setting $\tau=\sigma\cdot\left( i j \right)$ , the second sum is

$$
\underset{\sigma \in A_{n}}{\sum} a_{\sigma \left( 1 \right) 1} \dots  a_{\sigma \left( j \right) i} \dots  a_{\sigma \left( i \right) j} \dots  a_{\sigma \left( n \right) n} .
$$

Since $a_{k i}=a_{k j}$ $\forall k$ (as $c_{i}=c_{j}$ ), this sum equals the first and so cancels. That is,

$$
 \det  A = 0 .
$$

□

The multilinear and alternating properties determine how $ \det A$ changes under elementary column operations.

Proposition 2.  
If $\overset{̂}{A}$ is obtained from $A$ by

I.

$\left(\overset{̂}{c}\right)_{i}=\lambda c_{i}$ , then $ \det \overset{̂}{A}=\lambda \det A$ .

(II)

$\left(\overset{̂}{c}\right)_{i}=c_{i}+\lambda c_{j}$ ( $j\neq i$ ), then $ \det \overset{̂}{A}= \det A$ .

(III)

$c_{i}\leftrightarrowc_{j}$ ( $j\neq i$ ), then $ \det \overset{̂}{A}=- \det A$ .

Proof.

I.

is part of multilinearity.

(II)

$$
\begin{align}
 \det \overset{̂}{A} & = &  \det \left( c_{1} , \dots  , c_{i} + \lambda c_{j} , \dots  , c_{n} \right) & \text{} \\ & = &  \det \left( c_{1} , \dots  , c_{i} , \dots  , c_{n} \right) & \text{} \\ & & +\lambda \det \left( c_{1} , \dots  , c_{j} , \dots  , c_{n} \right),\text{by mult. lin.} & \text{} \\ & = &  \det A+\lambda\cdot 0,\text{by alt.} & \text{} \\ & = &  \det A & \text{}
\end{align}
$$

(III)

$$
\begin{align}
0= &  \det \left( c_{1} , \dots  , c_{i} + c_{j} , \dots  , c_{i} + c_{j} , \dots  , c_{n} \right)\text{by alt.} & & \\ = &  \det \left( c_{1} , \dots  , c_{i} , \dots  , c_{i} , \dots  , c_{n} \right) & & \\ & +\dots i\dots j\dots \text{by mult. lin.} & & \\ & +\dots j\dots i\dots  & & \\ & +\dots i\dots j\dots  & & \\ = & 0+ \det A+ \det \overset{̂}{A}+0. & \square
\end{align}
$$

So $ \det \overset{̂}{A}=- \det A$ .

Corollary 3.  
If $\overset{̂}{A}$ is obtained from $A$ by EROs (or ECOs), then

$$
 \det  \overset{̂}{A} \neq 0 \Leftrightarrow  \det  A \neq 0 .
$$

Proof. Suppose that $\overset{̂}{A}$ is obtained from $A$ by EROs (or ECOs). By Proposition [4.2.2](#x23-36009r2), we have $ \det \overset{̂}{A}=\pm \det A$ or $ \det \overset{̂}{A}=\lambda \det A$ for some nonzero scalar $\lambda$ . So $ \det \overset{̂}{A}\neq 0\Leftrightarrow \det A\neq 0$ . □

Remark 4.  

*   As $ \det A^{T}= \det A$ , Proposition [4.2.2](#x23-36009r2) also holds when we replace the columns by rows.
*   Proposition [4.2.2](#x23-36009r2) (I) implies that if $A$ has a zero row or column, then $ \det A=0$ , which can also be deduced directly from the definition of determinant.
*   If $\overset{̂}{A}$ is obtained from $A$ by permuting the columns (or rows) by $\sigma\in S_{n}$ then repeatedly applying Proposition [4.2.2](#x23-36009r2) (III) gives
    
    $$
     \det  \overset{̂}{A} = \left( sgn \sigma \right)  \det  A .
    $$
    

Example 5.  

$$
\begin{align}
\begin{vmatrix} \begin{matrix}5 & 4 & 0 \\ -1 & 2 & 1 \\ 1 & -5 & 0\end{matrix} \end{vmatrix} & = & -\begin{vmatrix} \begin{matrix}5 & 4 & 0 \\ 1 & -5 & 0 \\ -1 & 2 & 1\end{matrix} \end{vmatrix}R_{2}\leftrightarrowR_{3} & \text{} \\ & = & -\left( - 5 \right)\begin{vmatrix} \begin{matrix}5 & 4 & 0 \\ -\frac{1}{5} & 1 & 0 \\ -1 & 2 & 1\end{matrix} \end{vmatrix}-\frac{1}{5}R_{2} & \text{} \\ & = & 5\begin{vmatrix} \begin{matrix}\frac{2 9}{5} & 0 & 0 \\ -\frac{1}{5} & 1 & 0 \\ -1 & 2 & 1\end{matrix} \end{vmatrix}R_{1}-4R_{2},\text{lower triangular} & \text{} \\ & = & 5\cdot\frac{2 9}{5}\cdot 1\cdot 1=29. & \text{}
\end{align}
$$

Recall that an RREF matrix $A^{′}$ of an $n\times n$ -matrix $A$ has the form $A^{′}=\begin{pmatrix} I & * \\ 0 & 0 \end{pmatrix}$ , i.e. there exists an invertible matrix $P$ such that

$$
\begin{align}
PA=\begin{pmatrix} \begin{matrix}I & * \\ 0 & 0\end{matrix} \end{pmatrix},\text{ i.e. }A=P^{- 1}\begin{pmatrix} \begin{matrix}I & * \\ 0 & 0\end{matrix} \end{pmatrix}. & & & \text{(1)}\text{}\text{}
\end{align}
$$

Theorem 6.  
$A\in M_{n , n}\left( \F \right)$ is invertible if and only if $ \det A\neq 0$ .

Proof. $A$ is invertible $\Leftrightarrow$ $A^{′}=PA$ [4.2.1](#x23-36022r4.2.1) is invertible (see Q2.3) $\Leftrightarrow$ $A^{′}=I$ the identity matrix $\Leftrightarrow$ $ \det A^{′}=1$ (here we need that $A^{′}$ is an RREF matrix and square) $\Leftrightarrow$ $ \det A\neq 0$ , by Corollary [4.2.3](#x23-36018r3). □

[[next](MA10210se18.html)] [[prev](MA10210se16.html)] [[prev-tail](MA10210se16.html#tailMA10210se16.html)] [[front](MA10210se17.html)] [[up](MA10210ch4.html#MA10210se17.html)]