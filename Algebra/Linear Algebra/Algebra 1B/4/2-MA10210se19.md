[[next](MA10210se20.html)] [[prev](MA10210se18.html)] [[prev-tail](MA10210se18.html#tailMA10210se18.html)] [[tail](#tailMA10210se19.html)] [[up](MA10210ch4.html#MA10210se19.html)]

### 4.4 [Minors, adjugates and inverses](MA10210.html#QQ2-25-38)

Definition 1.  
For $A=\left( a_{i j} \right)\in M_{n , n}\left( \F \right)$ the $\left( i , j \right)$ -minor

$$
\left(\mu\right)_{i j} \left( A \right) =  \det  m_{i j} \left( A \right)
$$

where $m_{i j}\left( A \right)\in M_{n - 1 , n - 1}\left( \F \right)$ is obtained from $A$ by deleting row $i$ and column $j$ .

Proposition 2 (Column/row expansions of $ \det $ ).  

a.

For any fixed column $j$ ,

$$
 \det A = \sum_{i = 1}^{n} \left(\left( - 1 \right)\right)^{i + j} a_{i j} \left(\mu\right)_{i j} \left( A \right) .
$$

b.

For any fixed row $i$

$$
 \det  A = \sum_{j = 1}^{n} \left(\left( - 1 \right)\right)^{i + j} a_{i j} \left(\mu\right)_{i j} \left( A \right) .
$$

Example 3.  
Expanding about column 1,

$$
\begin{align}
 & & \begin{vmatrix} \begin{matrix}3 & 1 & 2 \\ 1 & 0 & -1 \\ 0 & 1 & 2\end{matrix} \end{vmatrix} & \text{} \\ & = & +3\begin{vmatrix} \begin{matrix}0 & -1 \\ 1 & 2\end{matrix} \end{vmatrix}-1\begin{vmatrix} \begin{matrix}1 & 2 \\ 1 & 2\end{matrix} \end{vmatrix}+0\begin{vmatrix} \begin{matrix}1 & 2 \\ 0 & -1\end{matrix} \end{vmatrix} & \text{} \\ & = & 3\left( 1 \right)-1\left( 0 \right)+0=3 & \text{}
\end{align}
$$

or, expanding about row 2,

$$
\begin{align}
 & & \begin{vmatrix} \begin{matrix}3 & 1 & 2 \\ 1 & 0 & -1 \\ 0 & 1 & 2\end{matrix} \end{vmatrix} & \text{} \\ & = & -1\begin{vmatrix} \begin{matrix}1 & 2 \\ 1 & 2\end{matrix} \end{vmatrix}+0\begin{vmatrix} \begin{matrix}3 & 2 \\ 0 & 2\end{matrix} \end{vmatrix}-\left( - 1 \right)\begin{vmatrix} \begin{matrix}3 & 1 \\ 0 & 1\end{matrix} \end{vmatrix} & \text{} \\ & = & -1\left( 0 \right)+0+1\left( 3 \right)=3 & \text{}
\end{align}
$$

Notation 4.  
For $A\in M_{m , n}\left( \F \right)$ and $v\in\left(\F\right)^{m}$ , let $A_{j}\left[ v \right]\in M_{m , n}\left( \F \right)$ be the result of replacing the $j$ th column of $A$ by $v$ .

Proof. Proof of [4.4.2](#x25-38002r2) (a) ((b) is similar).

Write

$$
\left(col\right)_{j} \left( A \right) = \sum_{i = 1}^{n} a_{i j} e_{i} .
$$

By multilinearity,

$$
 \det  A = \sum_{i = 1}^{n} a_{i j}  \det  A_{j} \left[ e_{i} \right] ,
$$

where, using Notation [4.4.4](#x25-38008r4),

$$
\begin{align}
 & j & & \text{} \\ A_{j}\left[ e_{i} \right]= & \begin{pmatrix} \begin{matrix}// & 0 & // \\ // & \vdots & // \\ // & 1 & // \\ // & \vdots & // \\ // & 0 & //\end{matrix} \end{pmatrix}i & & \text{}
\end{align}
$$

By $\left( i - 1 \right)$ many times of row swapping, moving row $i$ upwards to row $1$ and then $\left( j - 1 \right)$ many times of column swapping, moving column $j$ to column 1, we can bring the entry $1$ to the top left and apply Proposition [4.1.3](MA10210se16.html#x22-35012r3) to the resulting blockwise triangular matrix:

$$
\begin{align}
 \det A_{j}\left[ e_{i} \right] & = & \left(\left( - 1 \right)\right)^{i + j - 2} \det \begin{pmatrix} \begin{matrix}1 & & * \\ ̲ & ̲ & ̲ \\ 0 & & \\ \vdots & & m_{i j}\left( A \right) \\ 0 & & \end{matrix} \end{pmatrix} & \text{} \\ & = & \left(\left( - 1 \right)\right)^{i + j} \det m_{i j}\left( A \right), & \text{}
\end{align}
$$

as required. □

Definition 5.  
The adjugate of $A\in M_{n , n}\left( \F \right)$ is

$$
adj \left( A \right) = \left( b_{i j} \right) ,
$$

where

$$
b_{i j} = \left(\left( - 1 \right)\right)^{i + j} \left(\mu\right)_{j i} \left( A \right) .
$$

Terminology: $\left(\left( - 1 \right)\right)^{i + j}\left(\mu\right)_{i j}\left( A \right)$ is called the $\left( i , j \right)$ -cofactor of $A$ . In these terms, $adj\left( A \right)$ is the transpose of the matrix of cofactors.

Example 6.  
Let

$$
\begin{align}
A = \begin{pmatrix} a & b \\ c & d \end{pmatrix} .
\end{align}
$$

Then the minors are

$$
\begin{align}
\left(\mu\right)_{1 1}\left( A \right)=d, & \left(\mu\right)_{1 2}\left( A \right)=c, & & \text{} \\ \left(\mu\right)_{2 1}\left( A \right)=b, & \left(\mu\right)_{2 2}\left( A \right)=a, & & \text{}
\end{align}
$$

so matrix of cofactors is

$$
\begin{align}
A = \begin{pmatrix} d & -c \\ -b & a \end{pmatrix} ,
\end{align}
$$

and the adjugate is

$$
\begin{align}
adj A = \begin{pmatrix} d & -b \\ -c & a \end{pmatrix} .
\end{align}
$$

Theorem 7.  

$$
\left( adj A \right) \cdot A = \left(  \det  A \right) \cdot I .
$$

Proof. Need to show

$$
\begin{align}
\sum_{i = 1}^{n} b_{k i} a_{i j} = \left\{\begin{matrix}  \det A & k=j \\ 0 & k\neq j \end{matrix}\right
\end{align}
$$

Case $k=j$ is Proposition [4.4.2](#x25-38002r2) (a).

For $k\neq j$ , let $\overset{̂}{A}$ be $A$ with column $k$ replaced by column $j$ . Then $\overset{̂}{A}$ has two equal columns, so

$$
 \det  \overset{̂}{A} = 0 .
$$

But expanding $ \det \overset{̂}{A}$ about column $k$ gives

$$
\sum_{i = 1}^{n} \left(\overset{̂}{b}\right)_{k i} \cdot \left(\overset{̂}{a}\right)_{i k} = 0 ,
$$

where

$$
\begin{align}
\left(\overset{̂}{b}\right)_{k i} & = & \left(\left( - 1 \right)\right)^{i + k}\left(\mu\right)_{i k}\left( \overset{̂}{A} \right) & \text{} \\ & = & \left(\left( - 1 \right)\right)^{i + k}\left(\mu\right)_{i k}\left( A \right)\left( * \right) & \text{} \\ & = & b_{k i}, & \text{}
\end{align}
$$

the equality $\left( * \right)$ follows from the fact that $\overset{̂}{A}$ and $A$ are equal apart from $\left(col\right)_{k}$ . On the other hand $\left(\overset{̂}{a}\right)_{i k}=a_{i j}$ by construction, so we get the desired formula. □

Using the same the same strategy as in the proof of Theorem [4.4.7](#x25-38014r7), we can show that

$$
A adj A = I
$$

as well. Therefore if $ \det A\neq 0$ , then $adjA$ is a twosided inverse of $A$ . That is, we have the following.

Corollary 8.  
If $ \det A\neq 0$ , then $A$ is invertible and

$$
A^{- 1} = \frac{1}{ \det  A} adj A .
$$

Remark 9.  

*   The product formula of determinants and Theorem [4.4.7](#x25-38014r7)   give an alternative proof of Theorem [4.2.6](MA10210se17.html#x23-36023r6), which says
    
    $A$ is invertible if and only if $ \det A\neq 0$ .
    
    In addition, Theorem [4.4.7](#x25-38014r7) provides an explicit description of the inverse of $A$ , when $ \det A\neq 0$ .
    
*   Despite being explicit, this description of the inverse is very inefficient for computations when $n>3$ . However, one advantage of this argument is that it works equally well when $A$ belongs to $M_{n , n}\left( R \right)$ for a general ring $R$ : then $A$ has an inverse in $M_{n , n}\left( R \right)$ if and only if $ \det A$ is a unit in $R$ . The previous proof of Theorem [4.2.6](MA10210se17.html#x23-36023r6) used reduction to RREF, which relies on working over a field and not a ring.

Proposition 10.  
If $A,X\in M_{n , n}\left( \F \right)$ then

$$
A X = I \Leftrightarrow X A = I .
$$

Proof. By symmetry, it suffices to prove ‘ $\Rightarrow$’.

Suppose $XA=I$ . Then $Ax=0\Rightarrow x=XAx=0$ , so $\left(\phi\right)_{A}:\left(\F\right)^{n}\rightarrow\left(\F\right)^{n},x\rightarrow tailAx$ is injective. By Rank-Nullity theorem, $\left(\phi\right)_{A}$ must be an isomorphism. Therefore $A$ is invertible by Corollary [2.2.7](MA10210se7.html#x11-19020r7). Lemma [1.5.4](MA10210se5.html#x8-14001r4) [(a)](MA10210se5.html#x8-140021) implies that $X$ must be the unique inverse of $A$ . So $AX=0$ . □

Note that Q6.5 gives an alternative argument.

Example 11.  

1.

$2\times 2$ case $\begin{pmatrix} a & b \\ c & d \end{pmatrix}$

$$
\begin{align}
 & &  \det A=ad-bc & \text{} \\ & & adjA=\begin{pmatrix} \begin{matrix}d & -b \\ -c & a\end{matrix} \end{pmatrix}, & \text{}
\end{align}
$$

so

$$
\begin{align}
A^{- 1} = \frac{1}{a d - b c} \begin{pmatrix} d & -b \\ -c & a \end{pmatrix}
\end{align}
$$

which can be checked directly.

2.

$$
\begin{align}
 & & A=\begin{pmatrix} \begin{matrix}3 & 0 & 1 \\ 1 & 2 & 4 \\ -1 & 0 & 1\end{matrix} \end{pmatrix} & \text{} \\ & &  \det A=+2\begin{pmatrix} \begin{matrix}3 & 1 \\ -1 & 1\end{matrix} \end{pmatrix}=8,\text{(expansion about column }2\text{).} & \text{}
\end{align}
$$

$$
\begin{align}
adjA=\begin{pmatrix} \begin{matrix}+\begin{vmatrix} \begin{matrix}2 & 4 \\ 0 & 1\end{matrix} \end{vmatrix} & -\begin{vmatrix} \begin{matrix}0 & 1 \\ 0 & 1\end{matrix} \end{vmatrix} & +\begin{vmatrix} \begin{matrix}0 & 1 \\ 2 & 4\end{matrix} \end{vmatrix} \\ \\ -\begin{vmatrix} \begin{matrix}1 & 4 \\ -1 & 1\end{matrix} \end{vmatrix} & +\begin{vmatrix} \begin{matrix}3 & 1 \\ -1 & 1\end{matrix} \end{vmatrix} & -\begin{vmatrix} \begin{matrix}3 & 1 \\ 1 & 4\end{matrix} \end{vmatrix} \\ \\ +\begin{vmatrix} \begin{matrix}1 & 2 \\ -1 & 0\end{matrix} \end{vmatrix} & -\begin{vmatrix} \begin{matrix}3 & 0 \\ -1 & 0\end{matrix} \end{vmatrix} & +\begin{vmatrix} \begin{matrix}3 & 0 \\ 1 & 2\end{matrix} \end{vmatrix}\end{matrix} \end{pmatrix} & & & \text{}
\end{align}
$$

so

$$
\begin{align}
A^{- 1} = \frac{1}{8} \begin{pmatrix} 2 & 0 & -2 \\ -5 & 4 & -11 \\ 2 & 0 & 6 \end{pmatrix}
\end{align}
$$

Check:

$$
\begin{align}
\frac{1}{8} \begin{pmatrix} 2 & 0 & -2 \\ -5 & 4 & -11 \\ 2 & 0 & 6 \end{pmatrix} \begin{pmatrix} 3 & 0 & 1 \\ 1 & 2 & 4 \\ -1 & 0 & 1 \end{pmatrix} = \frac{1}{8} \begin{pmatrix} 8 & 0 & 0 \\ 0 & 8 & 0 \\ 0 & 0 & 8 \end{pmatrix} = I , \text{the identity matrix} .
\end{align}
$$

[[next](MA10210se20.html)] [[prev](MA10210se18.html)] [[prev-tail](MA10210se18.html#tailMA10210se18.html)] [[front](MA10210se19.html)] [[up](MA10210ch4.html#MA10210se19.html)]