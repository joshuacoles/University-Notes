[[next](MA10210se11.html)] [[prev](MA10210se9.html)] [[prev-tail](MA10210se9.html#tailMA10210se9.html)] [[tail](#tailMA10210se10.html)] [[up](MA10210ch2.html#MA10210se10.html)]

### 2.5 [Coordinates and representing linear maps/operators by matrices](MA10210.html#QQ2-14-23)

Definition 1.  
Let $\alpha:v_{1},dots,v_{n}$ be a basis. For $w\in V$ , write

$$
w = \underset{i}{\sum} \left(\lambda\right)_{i} v_{i} .
$$

We call the vector

$$
\lambda = \left( \left(\lambda\right)_{1} , \dots  , \left(\lambda\right)_{n} \right) \in \left(ğ”½\right)^{n}
$$

the coordinate vector $w$ with respect to the basis $\alpha$ .

In other words, the vector $\lambda=\phi_{\alpha}^{- 1}\left( w \right)$ is the coordinate vector of $w$ with respect to the basis $\alpha$ . Note that here $\left(\phi\right)_{\alpha}$ is an isomorphism, as $\alpha$ is a basis.

Example 2.  

*   Recall the standard basis $e_{1},\dots ,e_{n}$ of $\left(ğ”½\right)^{n}$ .
    *   For any $x\in\left(ğ”½\right)^{n}$ , the coordinate vector representing $x$ with respect to the standard basis is $x$ itself, because $x=\left(\sum\right)_{i}x_{i}e_{i}$ .
    *   Consider the case $n=2$ . Then $\alpha:e_{1}+e_{2},e_{2}$ is a basis of $\left(ğ”½\right)^{2}$ as well. The coordinate vector of $x=\left( 1 , 1 \right)\in\left(ğ”½\right)^{2}$ with respect to $\alpha$ is $\left( 1 , 0 \right)$ , as
        
        $$
        x = 1 \cdot \left( e_{1} + e_{2} \right) + 0 \cdot e_{2} .
        $$
        
    *   For any basis $\alpha:v_{1},\dots ,v_{n}$ of $V$ , the coordinate vector of $v_{i}$ wrt $\alpha$ is the elementary vector $e_{i}$ . For instance,
        
        $$
        v_{1} = 1 \cdot v_{1} + 0 \cdot v_{2} + . . . + 0 \cdot v_{n} , v_{2} = 0 \cdot v_{1} + 1 \cdot v_{2} + . . . + 0 \cdot v_{n} ,
        $$
        
        so the coordinate vectors of $v_{1}$ , $v_{2}$ wrt $\alpha$ is $e_{1}$ and $e_{2}$ , respectively.
        
*   Let $V\leq C^{2}\left( â„ \right)$ be the subspace of functions $f:â„\rightarrowâ„$ such that
    
    $$
    \frac{d^{2} f}{d x^{2}} + f = 0 .
    $$
    
    Define $f_{1},f_{2},g\in V$ by
    
    $$
    f_{1} \left( x \right) = cos \left( x \right) , f_{2} \left( x \right) = sin \left( x \right) , g \left( x \right) = cos \left(x + \frac{\pi}{3}\right) .
    $$
    
    Note that the list $\alpha:f_{1},f_{2}$ is a basis of $V$ (cf.Â Methods IA). Since
    
    $$
    g \left( x \right) = cos \left( x \right) cos \left( \frac{\pi}{3} \right) - sin \left( x \right) sin \left( \frac{\pi}{3} \right) = \frac{1}{2} f_{1} \left( x \right) - \frac{\sqrt{3}}{2} f_{2} \left( x \right) \text{ for all } x \in â„
    $$
    
    the coordinate vector representing $g$ with respect to $\alpha$ is $\left(\frac{1}{2} , - \frac{\sqrt{3}}{2}\right)\inâ„^{2}$ .
    

Now suppose that we have two vector spaces $V$ , $W$ and that

$V$ has a basis $\alpha:v_{1},\dots ,v_{n}$ $\leftrightarrow$ $\left(\phi\right)_{\alpha}:\left(ğ”½\right)^{n}\rightarrow _{}^{\cong}V$

$W$ has a basis $\beta:w_{1},\dots ,w_{m}$ $\leftrightarrow$ $\left(\phi\right)_{\beta}:\left(ğ”½\right)^{m}\rightarrow _{}^{\cong}W$ .

Definition 3.  
Say the matrix $A=\left( a_{i j} \right)\in M_{m , n}\left( ğ”½ \right)$ represents the linear map $\psi:V\rightarrow W$ with respect to the bases $\alpha$ and $\beta$ if

$$
\psi \left( v_{j} \right) = \underset{i}{\sum} a_{i j} w_{i} , \forall j .
$$

Note that, as $\beta$ is a basis, the matrix $A$ in Definition [2.5.3](#x14-23003r3)Â  is unique.

Remark 4.  
Following the definition of $A$ , we have the following diagram,

$e_{j}$

$\rightarrow _{}^{\left(\phi\right)_{A}}$

$\left(\sum\right)_{i}a_{i j}e_{i}$

Â 

Â 

Â 

$\left(\phi\right)_{\alpha}â†“$

$â†“\left(\phi\right)_{\beta}$

Â 

Â 

Â 

$v_{j}$

$\rightarrow _{}^{ \psi }$

$\left(\sum\right)_{i}a_{i j}w_{i}$

That is, the following diagram commutes.

$\left(ğ”½\right)^{n}$

$\rightarrow _{}^{\left(\phi\right)_{A}}$

$\left(ğ”½\right)^{m}$

Â 

Â 

Â 

$\left(\phi\right)_{\alpha}â†“$

$â†“\left(\phi\right)_{\beta}$

Â 

Â 

Â 

$V$

$\rightarrow _{}^{ \psi }$

$W$

That is,

$$
\psi=\left(\phi\right)_{\beta}\circ\left(\phi\right)_{A}\circ\phi_{\alpha}^{- 1}
$$

(1)

or

$$
\left(\phi\right)_{A}=\phi_{\beta}^{- 1}\circ\psi\circ\left(\phi\right)_{\alpha}.
$$

(2)

In fact, we can use either (1) or (2) to define the matrix $A$ in Definition [2.5.3](#x14-23003r3).

Definition 5.  

(1)

A linear operator is a linear map $\phi:V\rightarrow V$ , i.e.Â is a linear map with the domain and codomain the same vector space.

(2)

Let one $\alpha:v_{1},\dots ,v_{n}$ be a basis of $V$ , an $A\in M_{n , n}\left( ğ”½ \right)$ is said to represent the linear operator $\psi:V\rightarrow V$ with respect to $\alpha$ if

$$
\psi \left( v_{j} \right) = \underset{i}{\sum} a_{i j} v_{i} .
$$

Note that this matrix $A$ is unique as in Definition [2.5.3](#x14-23003r3).

Remark 6.  
As in Remark [2.5.4](#x14-23004r4), we have the following commutative diagram

$\left(ğ”½\right)^{n}$

$\rightarrow _{}^{\left(\phi\right)_{A}}$

$\left(ğ”½\right)^{n}$

Â 

Â 

Â 

$\left(\phi\right)_{\alpha}â†“$

$â†“\left(\phi\right)_{\alpha}$

Â 

Â 

Â 

$V$

$\rightarrow _{}^{ \psi }$

$V$

and the matrix $A$ in Definition [2.5.5](#x14-23007r5) can be defined by

$$
\left(\phi\right)_{A} = \phi_{\alpha}^{- 1} \circ \psi \circ \left(\phi\right)_{\alpha} .
$$

Example 7.  
Let

$$
\begin{align}
 & & V=\left\{ \text{polynomials degree }\leq 3\text{} \right\}\leqğ”½\left[ X \right] & \text{} \\ & & \psi:V\rightarrow V:P\rightarrow tail\frac{d P}{d X}, & \text{}
\end{align}
$$

then $1,X,X^{2},X^{3}$ is a basis of $V$ and

$$
\begin{align}
 & & \frac{d}{d X}\left( 1 \right)=0; & \text{} \\ & & \frac{d}{d X}\left( X \right)=1; & \text{} \\ & & \frac{d}{d X}\left( X^{2} \right)=2X; & \text{} \\ & & \frac{d}{d X}\left( X^{3} \right)=3X^{2}. & \text{}
\end{align}
$$

Thus, the matrix representing $\psi=\frac{d}{d X}$ is

$$
\begin{align}
A = \begin{pmatrix} 0 & 1 & 0 & 0 \\ 0 & 0 & 2 & 0 \\ 0 & 0 & 0 & 3 \\ 0 & 0 & 0 & 0 \end{pmatrix}
\end{align}
$$

Check:

$$
A \begin{pmatrix} a_{0} \\ a_{1} \\ a_{2} \\ a_{3} \end{pmatrix} = \begin{pmatrix} a_{1} \\ 2a_{2} \\ 3a_{3} \\ 0 \end{pmatrix}
$$

represents the equation

$$
\psi \left( a_{0} 1 + a_{1} X + a_{2} X^{2} + a_{3} X^{3} \right) = a_{1} 1 + 2 a_{2} X + 3 a_{3} X^{2} .
$$

[[next](MA10210se11.html)] [[prev](MA10210se9.html)] [[prev-tail](MA10210se9.html#tailMA10210se9.html)] [[front](MA10210se10.html)] [[up](MA10210ch2.html#MA10210se10.html)]