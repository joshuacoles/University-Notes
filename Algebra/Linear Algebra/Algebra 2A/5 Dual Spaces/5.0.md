### Chapter 5 Duality

#### 5.1 Dual spaces

Recall from [[Theorem 1.6]]: if $V$ and $W$ are vector spaces over $\F$ then the set $L(V,W)$ of linear maps from $V$ to $W$ is also a vector space under pointwise addition and scalar multiplication. In this chapter we will study the special case where $W=\F$ the field of scalars.

###### Definition

. Let $V$ be a vector space over $\F$. The _dual space $V^{*}$ of $V$_ is

$\seteqnumber{0}{5.}{0}$

$$ V^{\*}:=L(V,\F )=\set {\alpha :V\to \F \st \text {$\alpha $ is linear}}. $$

Elements of $V^{*}$ are called _linear functionals_ or (less often) _linear forms_.

Let us spell this out. An element $\alpha \in V^{*}$ is a function $\alpha :V\to \F$ which is linear:

$\seteqnumber{0}{5.}{0}$

$$ \alpha (v_1+\lambda v_2)=\alpha (v_1)+\lambda \alpha (v_2), $$

for all $v_1,v_2\in V$ and $\lambda \in \F$. The addition and scalar multiplication on the right are the field addition and multiplication in $\F$.

The dual space $V^{*}$ is a vector space (indeed a subspace of $\F ^V$) under pointwise addition and scalar multiplication. Thus:

$\seteqnumber{0}{5.}{0}$

$$ \begin{align*} (\alpha \_1+\alpha \_2)(v)&:=\alpha \_1(v)+\alpha \_2(v)\\ (\lambda \alpha )(v)&:=\lambda (\alpha (v)), \end{align*} $$ for all $\alpha ,\alpha _1,\alpha _2\in V^{*}$, $v\in V$ and $\lambda \in F$. Again, the algebraic operations on the right hand side of these formulae are those of the field $\F$.

###### Examples

.

When $V$ is finite-dimensional, so is $V^{*}$. Indeed:

- [[Proposition 5.1]]. Let $V$ be a finite-dimensional vector space with basis $\lst {v}1n$.

  Define $\dlst {v}1n\in V^{*}$ by setting

  $\seteqnumber{0}{5.}{0}$

  $$ v*i^{\*}(v_j)=\delta *{ij}\in \F $$

  and extending by linearity (thus applying [[Proposition 1.7]]).

  Then $\dlst {v}1n$ is a basis of $V^{*}$ called the _dual basis to $\lst {v}1n$_.

- Proof. Here is the key computation: if $\sum _{i=1}^n\lambda _iv^{*}_i\in V^{*}$ is a linear combination of the $v^{*}_i$ then evaluating on $v_j$ gives

  $\seteqnumber{0}{5.}{0}$

  $$ \sum _{i=1}^n\lambda \_iv^{\*}\_i(v_j)=\sum _{i=1}^n\lambda _i\delta _{ij}=\lambda \_j. $$

  In particular, if $\sum _{i=1}^n\lambda _iv^{*}_i=0$ then each $\lambda _j=0(v_j)=0$ and $\dlst {v}1n$ are linearly independent.

  Now let $\alpha \in V^{*}$ and set $\lambda _i=\alpha (v_i)$, for $\bw 1in$. Then $\alpha$ and $\sum _{i=1}^n\lambda _iv_i^{*}$ agree on each $v_j$ and so everywhere:

  $\seteqnumber{0}{5.}{0}$

  $$ \alpha =\sum \_{i=1}^n\alpha (v_i)v_i^{\*}. $$

  Thus $\dlst {v}1n$ span. □

- Remark. We have met these $v^{*}_i$ before, perhaps without realising it. Write $v\in V$ in terms of the $\lst {v}1n$: $v=\sum _{j=1}^n\lambda _jv_j$. Then

  $\seteqnumber{0}{5.}{0}$

  $$ v*i^{\*}(v)=\sum *{j=1}^n\lambda \_jv_i^{\*}(v_j)=\lambda \_i. $$

  Thus $v^{*}_i$ is the _$i$-th coordinate function on $V$ with respect to $\lst {v}1n$_.

  In particular, applying this to the standard basis $\lst {e}1n$ of $\F ^{n}$, we see that, for $x=(\lst {x}1n)\in \F ^n$, $e_i^{*}(x)=x_i$ so that any $\alpha \in (\F ^n)^{*}$ is given by

  $\seteqnumber{0}{5.}{0}$

  $$ \alpha (x)=\lc {\alpha }x1n $$

  with $\alpha _i=\alpha (e_i)$.

- [[Corollary 5.2]]. If $V$ is finite-dimensional then $\dim V=\dim V^{*}$.

When $V$ is an inner product space also, we get a complete understanding of $V^{*}$:

- [[Theorem 5.3]] (Riesz Representation Theorem). Let $V$ be a finite-dimensional inner product space and $\alpha \in V^{*}$. Then there is a unique $w\in V$ such that

  $\seteqnumber{0}{5.}{0}$

  $$ \alpha (v)=\ip {w,v}, $$

  for all $v\in V$. Thus $\alpha =\alpha _w$.

  Indeed, if $\lst {u}1n$ is an orthonormal basis of $V$ then

  $\seteqnumber{0}{5.}{0}$

  $$ \label {eq:6} w=\sum \_{i=1}^n\overline {\alpha (u_i)}u_i. $$

- Proof. With $w$ defined by (5.1) and $v\in V$, we have

  $\seteqnumber{0}{5.}{1}$

  $$ \begin{align*} \ip {w,v}&=\sum *{i=1}^n\alpha (u_i)\ip {u_i,v}\\ &=\alpha (\sum *{i=1}^n\ip {u_i,v}u_i)=\alpha (v) \end{align*} $$ where we have used the sesquilinearity of the inner product and [[Lemma 3.3]].

  For uniqueness, if $w'$ had the same property, we would have $\ip {w-w',v}=\alpha (v)-\alpha (v)=0$, for all $v\in V$, so that $w=w'$ by the Nondegeneracy [[Lemma 4.1]]. □

- Remark. How did we magic up formula (5.1) for $w$? We had to have $\ip {w,u_i}=\alpha (u_i)$ but $w=\sum _{i=1}^n\ip {u_i,w}u_i$ by [[Lemma 3.3]].

###### Example

. Fix $d\in \N$ and let $V\leq C^0[-1,1]$ be given by

$\seteqnumber{0}{5.}{1}$

$$ V=\set {p\in C^0[-1,1]\st \text {$p$ is a polynomial of degree no more than $d$}}. $$

Then $V$ is a finite-dimensional inner product space with inner product

$\seteqnumber{0}{5.}{1}$

$$ \ip {p,q}=\int \_{-1}^1pq. $$

Define $\alpha :V\to \R$ by $\alpha (p)=p(0)+p'(1/\sqrt {2})$. We have already noted that $\alpha \in V^{*}$.

So [[Theorem 5.3]] tells us that there is a $q\in V$ such that $\alpha (p)=\ip {q,p}$, for all $p\in V$. Otherwise said, there is a clever polynomial $q$ of degree $d$ such that

$\seteqnumber{0}{5.}{1}$

$$ \int \_{-1}^1qp=p(0)+p'(1/\sqrt {2}), $$

for all polynomials of degree no more than $d$!

A basic question is how big is $V^{*}$: are there enough linear functionals to detect all elements of $V$? The answer is yes and the key is the following theorem:

- [[Theorem 5.4]] (Sufficiency principle). Let $V$ be a vector space and $v\in V$. Then $\alpha (v)=0$, for all $\alpha \in V^{*}$, if and only if $v=0$.

- Proof. A complete proof requires a tool from set theory called Zorn’s Lemma, equivalent to the Axiom of Choice, which has the faintly controversial property that it is logically independent from the usual axioms of set theory (so you can choose to believe it or not without running into a contradiction). Rather than get involved in all that we simply prove the result in two cases of interest.

  - (1) If $V$ is an inner product space and $v\in V$ is non-zero then $\alpha _v(v)=\ip {v,v}\neq 0$, where $\alpha _v\in V^{*}$ is given by $\alpha _v(w)=\ip {v,w}$.
  - (2) If $V$ is finite-dimensional, choose a basis $\lst {v}1n$. For $v\in V$, write $v=\lc \lambda {v}1n$. If $\alpha (v)=0$ for all $\alpha \in V^{*}$ then, in particular, for each $i$, $0=v_i^{*}(v)=\lambda _i$ so that $v=0$.

  □

- Exercise.1 Let $v\in V$ and $U\leq V$ with $v\notin U$. Show that there is $\alpha \in V^{*}$ such that $\alpha (v)\neq 0$ while $\alpha _{|U}=0$.

  **Hint**: apply [[Theorem 5.4]] to $V/U$.

We apply [[Theorem 5.4]] to get a converse to [[Proposition 5.1]]:

- [[Proposition 5.5]]. Let $V$ be a finite-dimensional vector space and $\lst {\alpha }1n$ a basis of $V^{*}$. Then there is a basis $\lst {v}1n$ of $V$ such that

  $\seteqnumber{0}{5.}{1}$

  $$ \alpha _i(v_j)=\delta _{ij}. $$

  Thus $\alpha _i=v^{*}_i$, for $\bw 1{i}n$.

- Proof. Define a linear map $\phi :V\to \F ^n$ by

  $\seteqnumber{0}{5.}{1}$

  $$ \phi (v)=(\alpha \_1(v),\dots ,\alpha \_n(v)) $$

  and observe that $v\in \ker \phi$ if and only if $\alpha _i(v)=0$, for $\bw 1in$, whence, since any $\alpha \in V^{*}$ is a linear combination of the $\alpha _i$, $\alpha (v)=0$, for all $\alpha \in V^{*}$. We deduce from [[Theorem 5.4]] that $v=0$ so that $\ker \phi =\set 0$ and $\phi$ is injective. On the other hand, $\dim V=\dim V^{*}=n=\dim \F ^n$ so that $\phi$ is an isomorphism.

  Now set $v_i=\phi ^{-1}(e_i)$, $\bw 1in$, to get a basis of $V$ since $\lst {e}1n$ is a basis of $\F ^n$. Then

  $\seteqnumber{0}{5.}{1}$

  $$ \phi (v_j)=(\alpha \_1(v_j),\dots ,\alpha \_n(v_j))=e_j=(0,\dots ,1,\dots ,0), $$

  where the $1$ is in the $j$-th slot. Otherwise said, $\alpha _i(v_j)=\delta _{ij}$ as required. □

Since the dual space $V^{*}$ is a vector space, we can contemplate its dual space $V^{**}:=(V^{*})^{*}$, the _double dual of $V$_. This is closely related to $V$ itself. Indeed, each $v\in V$ defines a linear map $\ev (v):V^{*}\to \F$ by evaluation at $v$:

$\seteqnumber{0}{5.}{1}$

$$ \ev (v)(\alpha ):=\alpha (v)\in \F . $$

- Exercises.2
- - 1. $\ev (v)$ is indeed linear: for $\alpha ,\beta \in V^{*}$ and $\lambda \in \F$,

    $\seteqnumber{0}{5.}{1}$

    $$ \ev (v)(\alpha +\lambda \beta )=\ev (v)(\alpha )+\lambda \ev (v)(\beta ). $$

    Thus $\ev (v)\in V^{**}$.

  - 2. We therefore have a map $\ev :V\to V^{**}$. Show that $\ev$ is linear: that is,

    $\seteqnumber{0}{5.}{1}$

    $$ \ev (v+\lambda w)=\ev (v)+\lambda \ev (w), $$

    for all $v,w\in V$, $\lambda \in \F$. To spell it out even more, this means

    $\seteqnumber{0}{5.}{1}$

    $$ \ev (v+\lambda w)(\alpha )=\ev (v)(\alpha )+\lambda \ev (w)(\alpha ), $$

    for all $\alpha \in V^{*}$.

  - 3. $\ev$ is injective (use [[Theorem 5.4]]) and so, when $V$ is finite-dimensional, an isomorphism since $\dim V=\dim V^{*}=\dim V^{**}$.

Thus:

- [[Theorem 5.6]]. If $V$ is a finite-dimensional vector space then $\ev :V\to V^{**}$ is an isomorphism.

- Remark. In general, a vector space for which $\ev :V\to V^{**}$ is an isomorphism is said to be _reflexive_.

1 Question 5 on sheet 8.

2 Question 7 on sheet 8.
