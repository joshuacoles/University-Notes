ALGEBRA 2B (MA20217): MAIN IDEAS

This is a list of the main ideas of the course, in the order in which the occur in the lectures and notes.

Section I.

I.11: what a ring is. You are able to add, multiply and subtract: there is a 0 and (our convention) a 1, and multiplication and addition behave sensibly both individually and together.

I.15: unit. In a ring, you can’t necessarily divide (i.e. “unmultiply”): $a^{-1}$ doesn’t have to exist. If it does exist, $a$ is called a unit.

I.20: integral domain. In an integral domain, if you get zero out of a multiplication, you must have put a zero in somewhere. To avoid various unpleasantnesses, we insist on commutative rings here, and $0\neq 1$.

I.21: division ring. In a division ring, everything is a unit, except $0$ of course.

I.22: field. A commutative division ring. So you are now allowed to add, multiply, subtract, and divide by anything that isn’t zero, and everything is commutative.

I.27: (formal) power series. Basically just a sequence of elements of $R$, but written down as $a_0+a_1t+a_2t^2+\dots$ instead of $(a_0,a_1,a_2,\dots )$. They make a ring, multiplying the way you would expect from how you multiply out brackets.

I.28: polynomials. Power series that stop. A polynomial has only finitely many terms: the degree is the highest power of $t$ that you see. Try not to ask what the degree of $0$ is.

I.29: evaluation map. Substitute your favourite element of $R$ for $t$.

I.30: subring. A subset of a ring, closed under multiplication and subtraction, or, if you prefer, under multiplication, addition and negation (taking $-a$). With our conventions, need not have a $1$, so not quite a ring in its own right necessarily.

I.38: ideal. A subset of a ring, closed under addition and subtraction and also under multiplication, not just by other elements of the ring, but by anything. If you imagine for a moment that $a$ really means $0$, then $ab$ must mean $0$ as well: similarly, if $a$ is in $I$, then $ab$ must be in $I$ as well.

I.41: principal ideal. In a commutative ring, the set of multiples of some element $a$, i.e. $\{ar\mid r\in R\}$. Also called the ideal generated by $a$.

I.45: quotient ring. The set of classes $a+I$, where $I$ is an ideal in $R$ and $a\in R$, with addition and multiplication inherited from $R$.

Section II.

II.2 ring homomorphism. A map from one ring to another that preserves the ring operations. So if $\varphi \colon R \to S$ is a ring homomorphism, that means you can do a computation in $R$ and use $\varphi$ to export the answer to $S$, or you can export the parts and do the computation in $S$, and you’ll get the same answer either way.

II.9 kernel. The kernel of a ring homomorphism $\varphi$ is the set of things that it sends to $0$.

II.10 image. The image of $\varphi$ is the set of things that are outputs of $\varphi$ (exactly as in set theory).

II.13 quotient map. The map $a\mapsto a+I$, going from $R$ to $R/I$.

II.16 any homomorphism factors as quotient by $I$ followed by something else, if $I$ is an ideal in the kernel.

II.17 isomorphism. A pair of mutually inverse homomorphisms. Two rings are isomorphic if an isomorphism between them exists.

II.19 a special case of II.16. Now $I$ actually is the kernel, and what it says is that any homomorphism is actually “kill the kernel, and then put the quotient $R/\Ker \varphi$ in $S$ somewhere”.

II.20 there are no interesting homomorphisms from a field.

II.23 characteristic. The number of $1$s you have to add before you get back to $0$, or $0$ if that never happens.

II.29 sum, product and intersection of ideals. Sum and intersection are what you think, but for product it’s not enough to look at the set of all $ab$ with $a\in I$ and $b\in J$ because that’s not an ideal, so you have to allow sums of products as well.

II.33 direct product. A copy of $R$ in your left hand and a copy of $S$ in your right hand.

II.34 Chinese Remainder Theorem. If $I+J=R$ then $R/(I\cap J)$ is just $R/I \times R/J$.

II.38 field of fractions. Start with an integral domain (this is important) and simply give yourself an element called $a^{-1}$ (or $1/a$ if that isn’t too confusing) you haven’t already got one (and $a\neq 0$). In other words, allow yourself to divide, except by zero of course.

II.40 field of rational functions. Given a field $K$, the field of rational functions is ${\cQ }(K[t])$, i.e. fractions with polynomials allowed in numerator and denominator.

Section III.

III.3 cancellation property. Being an integral domain is the same as being allowed to cancel nonzero factors in equations. We are in an integral domain all though Section III.

III.4 divides. Means what you think it means.

III.5 “divides” means “generates a bigger ideal”.

III.8 prime and irreducible. $p$ is prime if it can only divide a product by dividing one of the factors. It is irreducible if it won’t split into (non-unit) factors itself.

III.10 primes are irreducible. This is true in any integral domain.

III.11 Euclidean valuation. A substitute for modulus. Fairly unusual to have it, but degree of polynomials is another example. The advantage is that you can now prove things by induction on how “big” they are.

III.15 PID. Stands for Principal Ideal Domain: it’s an integral domain, and the only ideals are principal ideals.

III.15 Fields don’t have interesting ideals.

III.16 Euclidean domains (integral domains with a Euclidean valuation) are PIDs

III.19 coprime. Two elements of a PID are coprime if anything that divides both of them has to be a unit.

III.20 another look at coprime. …or if the ideal they generate together is the whole of $R$: in particular, if you can make $1$ from them.

III.23 UFD. Stands for Unique Factorisation Domain. Means that any element can be written as a product of irreducibles, and essentially in only one way (you can mess about with units and the order if you like).

III.26 in a UFD, irreducibles are prime. Not true for arbitrary domains, unlike the other direction.

III.27 PIDs are UFDs.

III.30 UFDs do not have to be PIDs.

III.33 finitely generated. An ideal $I$ is finitely generated if it is $\langle a_1,\ldots , a_n\rangle$ for some finite collection of $a_i$s.

III.35 finitely generated ideals in a UFD are contained in some unique smallest principal ideal.

III.37 primitive polynomial. A polynomial in $R[t]$ is primitive if the coefficients don’t all have a common factor (except units).

III.40 products of primitive polynomials are primitive.

III.41 irreducible polynomials in $R[t]$ are either constant (and irreducible in $R$) or primitive and still irreducible even if you allow yourself to try to factorise them using coefficients from ${\cQ }(R)$.

III.42 if $R$ is a UFD, so is $R[t]$.

Section IV.

IV.1 $K$-algebra. A $K$-vector space that is also a ring (compatibly with the multiplication from $K$), or, what comes to the same thing, a ring with a copy of $K$ inside it.

IV.5 the quaternions. A fun non-commutative ring, found on a bridge in Dublin.

IV.7 polynomial rings in many variables. You are used to them

IV.12 polynomial rings are UFDs, but not usually PIDs.

IV.13 subfield and field extension. What they say: one field contained in another.

IV.16 algebraic element. If $L:K$ is a field extension then $a\in L$ is algebraic if it is a root of a polynomial with $K$ coefficients.

IV.17 $K[a]$ is a field. If $a$ is algebraic, you don’t need to make $K(a)$: you’ve already got it. Secretly, that’s because you have some equation like $\alpha _n a^n+\cdots +\alpha _0=0$ so $\alpha _n a^{n-1}+\cdots +\alpha _0a^{-1}=0$ so $a^{-1}=-\alpha _0^{-1}(\alpha _na^{n-1}+\cdots +\alpha _1)$, but you have to be slightly more careful than that.

IV.20 adjoining algebraic elements. If you have a polynomial $p$ over $K$ and you haven’t already got a root of it, you can just give yourself one by working in $K[t]/\langle p\rangle$ instead. You do need $p$ to be irreducible.

IV.21 splitting fields. You can keep doing this until you’ve got all the roots you can expect.

IV.23 inner product. Like dot product. Just vector spaces at this stage.

IV.24 norm. Like, well, norm.

IV.26 normed $\RR$-algebra. Norm behaves properly when you multiply.

IV.30 there are only three normed $\RR$-algebras.

Section V.

V.1 endomorphism. A linear map from a $K$-vector space $V$ to itself. Also called a linear operator.

V.2 $\End (V)$ is a $K$-algebra.

V.3 matrices give endomorphisms and vice versa. But you have to fix a basis of $V$ to decide how.

V.5 you can substitute an endomorphism or a matrix into a polynomial.

V.8 when you do this you sometimes get zero.

V.9 monic polynomial. One that begins with $t^n$, rather than with $at^n$ for some arbitrary $a$.

V.11 minimum (or minimal) polynomial. The smallest-degree one that kills $\alpha$.

V.14 every eigenvalue is a root of $m_\alpha$. Or of any polynomial that kills $\alpha$ – “to kill $\alpha$, you have to kill all its eigenvalues”.

V.15 characteristic polynomial. The determinant of $\alpha -t\id$.

V.16 algebraic and geometric multiplicities. Respectively how often $\lambda$ is a root of $\chi _\alpha$ and how many independent $\lambda$-eigenvectors there are.

V.19 the Cayley-Hamilton Theorem. $\chi _\alpha (\alpha )=0$.

V.21 the roots of $m_\alpha$ are the eigenvalues. There are no others.

V.24 invariant subspace. One that is sent back to itself by $\alpha$.

V.26 direct sum of maps. Like direct product, you just do things independently.

V.31 cyclic subspace. Keep applying $\alpha$ to $v$ until you stop seeing anything new.

V.33 if there is only one eigenvalue $\lambda$, see what power of $\alpha -\lambda \id$ is actually zero. Find something that actually needs that much $\alpha -\lambda \id$ to kill it, and write it down along with all the things you get by applying $\alpha -\lambda \id$ to it repeatedly. This gives you a Jordan block.

V.36 do this again. This gives you JNF in this case of only one eigenvalue.

V.39 if the minimum polynomial factors into two coprime factors, that splits $V$ into a part where one factor is zero and a part where the other factor is zero. You prove this for images first, and then notice that the kernel of each is the image of the other, but that needs a dimension count (it uses rank-nullity).

V.40 Primary Decomposition. Factorise $m_\alpha$ into coprime factors as far as possible and break $V$ up into a piece belonging to each one.

V.41 diagonalisability. You get this if and only if the minimum polynomial has distinct roots.

V.43 generalised eigenspace. The space of things killed by a high enough power of $\alpha -\lambda \id$ (eigenvectors are the ones killed by one dose).

V.46 there is a basis of generalised eigenvectors.

V.47 JNF!