### Chapter 4 Linear operators on inner product spaces

###### Convention

. In this chapter, we once again take the field $\F$ of scalars to be either $\R$ or $\C$.

#### 4.1 Linear operators and their adjoints

##### 4.1.1 Linear operators and matrices

###### Definition

. Let $V$ be a vector space over $\F$. A _linear operator on $V$_ is a linear map $\phi :V\to V$.

The vector space of linear operators on $V$ is denoted $L(V)$ (instead of $L(V,V)$).

A special case of the analysis of §1.4.2 tell us that linear operators in the presence of a basis are closely related to square matrices: if $V$ is a finite-dimensional vector space over $\F$ with basis $\cB =\lst {v}1n$ and $\phi \in L(V)$ then the matrix of $\phi$ with respect to $\cB$ is the square matrix $A=(A_{ij})\in M_{n\times n}(\F )$ with

$\seteqnumber{0}{4.}{0}$

$$ \label {eq:12} \phi (v*j)=\sum *{i=1}^nA\_{ij}v_i, $$

for $\bw {1}jn$.

Equivalently, $\phi (\lc {x}v1n)=\lc {y}v1n$ where

$\seteqnumber{0}{4.}{1}$

$$ \by =A\bx . $$

##### 4.1.2 Adjoints

First a preliminary lemma:

- [[Lemma 4.1]] (Nondegeneracy Lemma). Let $V$ be an inner product space and $v\in V$. Then $\ip {v,w}=0$, for all $w\in V$, if and only if $v=0$.

- Proof. For the forward implication, take $v=w$ to get $\ip {v,v}=0$ and so $v=0$ by positive-definiteness of inner product.

  Conversely, if $v=0$, $\ip {v,w}=0$, for any $w\in V$, since the inner product is anti-linear in the first slot1. □

- Remark. To put this another way: $V^{\perp }=\set {0}$.

###### Definition

. Let $V$ be an inner product space and $\phi \in L(V)$. An _adjoint to $\phi$_ is a linear operator $\phi ^{*}\in L(V)$ such that, for all $v,w \in V$, we have

$\seteqnumber{0}{4.}{1}$

$$ \ip {\phi ^{\*}(v),w}=\ip {v,\phi (w)} $$

or, equivalently, by conjugate symmetry,

$\seteqnumber{0}{4.}{1}$

$$ \ip {w,\phi ^{\*}(v)}=\ip {\phi (w),v}. $$

Adjoints are well-behaved under most linear map constructions:

- [[Proposition 4.2]]. Let $V$ be an inner product space and suppose $\phi ,\psi \in L(V)$ have adjoints. Then $\phi \circ \psi$; $\phi +\lambda \psi$, $\lambda \in \F$; $\phi ^{*}$ and $\id _V$ all have adjoints given by:

  - (1) $(\phi \circ \psi )^{*}=\psi ^{*}\circ \phi ^{*}$ (note the change of order here!).
  - (2) $(\phi +\lambda \psi )^{*}=\phi ^{*}+\bar {\lambda }\psi ^{*}$.
  - (3) $(\phi ^{*})^{*}=\phi$.
  - (4) $\id _V^{*}=\id _V$.

- Proof. These are all easy exercises2. □

When $V$ is finite-dimensional, any $\phi \in L(V)$ has a unique adjoint:

- [[Proposition 4.3]]. Let $V$ be a _finite-dimensional_ inner product space and $\phi \in L(V)$ a linear operator. Then

  - (1) $\phi$ has a unique adjoint $\phi ^{*}$.
  - (2) Let $\lst {u}1n$ be an orthonormal basis of $V$ with respect to which $\phi$ has matrix $A$. Then $\phi ^{*}$ has matrix $A^{\dagger }:=\overline {A}^T$ (which is $A^T$ when $\F =\R$).

- Proof. For (1), let $\lst {u}1n$ be an orthonormal basis of $V$. [[Lemma 3.3]] tells us that any $u\in V$ can be written

  $\seteqnumber{0}{4.}{1}$

  $$ u=\sum \_{i=1}^n\ip {u_i,u}u_i. $$

  In particular, if $\phi ^{*}$ existed, we would have

  $\seteqnumber{0}{4.}{1}$

  $$ \phi ^{_}(v)=\sum \_{i=1}^n\ip {u_i,\phi ^{_}(v)}u*i =\sum *{i=1}^n\ip {\phi (u_i),v}u_i. $$

  Inspired by this, we _define_ $\phi ^{*}:V\to V$ by

  $\seteqnumber{0}{4.}{1}$

  $$ \label {eq:13} \phi ^{\*}(v)=\sum \_{i=1}^n\ip {\phi (u_i),v}u_i. $$

  We note that $\phi ^{*}$ so defined is linear since the inner product is linear in the second slot. Moreover, for $w\in V$, we have

  $\seteqnumber{0}{4.}{2}$

  $$ w=\sum \_{i=1}^n\ip {u_i,w}u_i $$

  whence

  $\seteqnumber{0}{4.}{2}$

  $$ \phi (w)=\sum \_{i=1}^n\ip {u_i,w}\phi (u_i). $$

  Thus,

  $\seteqnumber{0}{4.}{2}$

  $$ \begin{align*} \ip {\phi ^{*}(v),w}&=\sum _{i=1}^n\overline {\ip {\phi (u_i),v}}\ip {u_i,w}= \sum _{i=1}^n \ip {v,\phi (u*i)}\ip {u_i,w}\\ &=\ip {v,\sum *{i=1}^n\ip {u_i,w}\phi (u_i)}=\ip {v,\phi (w)}. \end{align*} $$ This establishes the existence of $\phi ^{*}$.

  For uniqueness, either observe that (4.2) uniquely determines $\phi ^{*}$, or better (because the argument works for infinite-dimensional $V$), suppose that $\phi$ has adjoints $\phi _1^{*}$ and $\phi _2^{*}$. Then we have

  $\seteqnumber{0}{4.}{2}$

  $$ \ip {\phi ^{_}\_1(v),w}=\ip {v,\phi (w)}=\ip {\phi \_2^{_}(v),w} $$

  so that $\ip {\phi _1^{*}(v)-\phi _2^{*}(v),w}=0$ and $\phi _1^{*}(v)=\phi _2^{*}(v)$ by the Nondegeneracy [[Lemma 4.1]].

  For (2), note that if $\psi \in L(V)$ has matrix $B$ with respect to $\lst {u}1n$ so that

  $\seteqnumber{0}{4.}{2}$

  $$ \psi (u*j)=\sum *{i=1}^nB\_{ij}u_i, $$

  then

  $\seteqnumber{0}{4.}{2}$

  $$ \ip {u*k,\psi (u_j)}=\sum *{i=1}^nB*{ij}\ip {u_k,u_i}=B*{kj}. $$

  Taking $\psi$ to be $\phi ^{*}$ and then $\phi$ in this, we see that if $C$ is the matrix of $\phi ^{*}$ then

  $\seteqnumber{0}{4.}{2}$

  $$ C*{kj}=\ip {u_k,\phi ^{\*}(u_j)}=\ip {\phi (u_k),u_j} =\overline {\ip {u_j,\phi (u_k)}}=\overline {A*{jk}}. $$

  Thus $C=A^{\dagger }$. □

- Remarks.
- - 1. [[Proposition 4.3]] along with [[Proposition 4.2]](2) tells us that when $V$ is finite-dimensional, $\phi \mapsto \phi ^{*}:L(V)\to L(V)$ is an anti-linear map (and so a linear map when $\F =\R$).
  - 2. The uniqueness part of [[Proposition 4.3]] holds even for infinite-dimensional $V$: if $\phi \in L(V)$ has an adjoint at all, it has only one.

###### Example

. Let $A\in M_{n\times n}(\R )$. Let us show that $(\phi _{A})^{*}=\phi _{A^T}$. Indeed:

$\seteqnumber{0}{4.}{2}$

$$ \phi \_{A^T}(y)\cdot x=(A^T\by )^T\bx =\by ^TA\bx =y\cdot \phi \_A(x) $$

where we have used the familiar identities $(AB)^T=B^TA^T$, for $B\in M_{n\times m}$, and $(A^T)^T=A$.

Similarly, when $\F =\C$, $(\phi _A)^{*}=\phi _{A^{\dagger }}$.

###### Definitions

.

- Remark. If $\phi$ has matrix $A$ with respect to an orthonormal basis of $V$ then [[Proposition 4.3]](2) tells us that $\phi$ is self-adjoint if and only if $A$ is Hermitian or symmetric (according to whether $\F$ is $\C$ or $\R$). Similarly, $\phi$ is skew-adjoint if and only if $A$ is skew-Hermitian or skew-symmetric.

###### Examples

. Using [[Proposition 4.2]], we get

- (i) $\id _V^{*}=\id _V$ so $\id _V$ is self-adjoint.
- (ii) $\phi ^{*}\circ \phi$ is self-adjoint: $(\phi ^{*}\circ \phi )^{*}=\phi ^{*}\circ (\phi ^{*})^{*}=\phi ^{*}\circ \phi$. Replacing $\phi$ by $\phi ^{*}$ shows that $\phi \circ \phi ^{*}$ is self-adjoint also.
- (iii) Exercise3: when $\F =\C$, $\phi$ is self-adjoint if and only if $i\phi$ is skew-adjoint (here $i=\sqrt {-1}$!).

1 To spell it out: $\ip {0,w}=\ip {0+0,w}=\ip {0,w}+\ip {0,w}$

2 Question 1 on sheet 6.

3 Question 3 on sheet 6.

##### 4.1.3 Linear isometries

###### Definition

. Let $V,W$ be inner product spaces with inner products $\ip {\, ,\,}_V$ and $\ip {\, ,\,}_W$ respectively. A linear map $\phi :V\to W$ is a _linear isometry_ if, for all $v_1,v_2\in V$,

$\seteqnumber{0}{4.}{2}$

$$ \ip {\phi (v_1),\phi (v_2)}\_W=\ip {v_1,v_2}\_V. $$

In this case we have that:

- • $\phi$ is _norm-preserving_: $\norm {\phi (v)}_W=\norm {v}_V$, for all $v\in V$.
- • $\phi$ is _distance-preserving_: $\norm {\phi (v_1)-\phi (v_2)}_W=\norm {v_1-v_2}_V$, for all $v_1,v_2\in V$, (since both sides equal $\norm {\phi (v_1-v_2)}_W$).

###### Example

. Let $\cB =\lst {u}1n$ be an orthonormal basis of an inner product space $V$. Then $\phi _{\cB }:\F ^n\to V$ is a linear isometry when $\ip {\, ,\,}_{\F ^n}$ is dot product. This is the content of [[Proposition 3.5]].

Let us now focus on the case where $V=W$ and is finite-dimensional.

- [[Proposition 4.4]]. Let $V$ be a finite-dimensional inner product space and $\phi \in L(V)$. Then $\phi$ is a linear isometry if and only if $\phi$ is an isomorphism with $\phi ^{-1}=\phi ^{*}$ (equivalently, $\phi ^{*}\circ \phi =\id _V=\phi \circ \phi ^{*}$).

- Proof. We prove the reverse implication first: if $\phi ^{-1}=\phi ^{*}$, then $\phi ^{*}\circ \phi =\id _V$ so that, for all $v,w\in V$,

  $\seteqnumber{0}{4.}{2}$

  $$ \ip {v,w}=\ip {v,\phi ^{\*}(\phi (w))}=\ip {\phi (v),\phi (w)}. $$

  Thus $\phi$ is a linear isometry.

  Conversely, if $\phi$ is a linear isometry then, for all $v,w\in V$,

  $\seteqnumber{0}{4.}{2}$

  $$ \ip {v,w}=\ip {\phi (v),\phi (w)}=\ip {\phi ^{\*}\circ \phi (v),w} $$

  so that $\ip {v-\phi ^{*}\circ \phi (v),w}=0$, for all $w\in V$. Thus by the nondegeneracy [[Lemma 4.1]], we get $v=\phi ^{*}\circ \phi =\id _V$, that is:

  $\seteqnumber{0}{4.}{2}$

  $$ \label {eq:14} \phi ^{\*}\circ \phi =\id \_V. $$

  Since $\id _V$ injects, $\phi$ injects also and so, by [[Proposition 1.9]], is an isomorphism4. Now apply $\phi ^{-1}$ on the right of both sides of (4.3) to yield $\phi ^{*}=\phi ^{-1}$. □

- Remark. If $V$ is infinite-dimensional, linear isometries $V\to V$ need not surject. For example: $Z:\ell _2\to \ell _{2}$ given by $(a_0,a_1,\dots )\mapsto (0,a_0,a_1,\dots )$ is a non-surjective isometry (exercise5!).

[[Proposition 4.4]] prompts some terminology:

###### Definitions

. Let $V$ be an inner product space over $\F$ and $\phi \in L(V)$. If $\phi$ is an isomorphism with $\phi ^{-1}=\phi ^{*}$, then say $\phi$ is:

- • an _orthogonal transformation_ if $\F =\R$;
- • a _unitary transformation_ if $\F =\C$.

The set of all orthogonal, resp. unitary transformations is denoted $\rO (V)$, resp. $\rU (V)$.

Let $A\in M_{n\times n}(\F )$.

- • $A$ is _orthogonal_ if $\F =\R$ and $A^TA=\I$;
- • $A$ is _unitary_ if $\F =\C$ and $A^{\dagger }A=\I$.

The set of all $n\times n$ orthogonal, resp. unitary matrices is denoted $\rO (n)$, resp. $\rU (n)$.

- Remarks.
- - 1. The argument of [[Proposition 4.4]] shows that $A$ is orthogonal if and only if $A$ is invertible with $A^{-1}=A^T$. Similarly $A$ is unitary if and only if $A$ is invertible with $A^{-1}=A^{\dagger }$.
  - 2. If $\phi$ has matrix $A$ with respect to an _orthonormal_ basis of $V$ then $\phi$ is an orthogonal or unitary transformation if and only if $A$ is an orthogonal or unitary matrix.

What sort of an object is $\rO (n)$ or $\rU (n)$? They are _groups_! Recall from Algebra 1A:

A _group_ is a set $G$ with a binary operation $G\times G\to G$, written $(g,h)\mapsto gh$, such that:

- • $(gh)k=g(hk)$, for all $g,h,k\in G$;
- • there is an element $1\in G$ such that $g1=1g=g$, for all $g\in G$. $1$ is the _neutral_ or _identity element_ of $G$.
- • Each $g\in G$ has an _inverse_ $g^{-1}$ such that $g^{-1}g=1=gg^{-1}$.

A _subgroup_ $H$ of a group $G$ is a non-empty subset $H\subset G$ which is closed under multiplication and inverses: whenever $h,k\in H$ then $hk\in H$ and $h^{-1}\in H$. We know that a subgroup is a group in its own right using the multiplication of $G$.

With our minds refreshed on these matters, we turn to some groups of matrices.

###### Definitions

. Let $V$ be a vector space. The _general linear group of $V$_, denoted $\GL (V)$, is:

$\seteqnumber{0}{4.}{3}$

$$ \GL (V):=\set {\phi \in L(V)\st \text {$\phi $ is an isomorphism}}. $$

Similarly, the _general linear group of $n\times n$ matrices over $\F$_, denoted $\GL (n,\F )$, is:

$\seteqnumber{0}{4.}{3}$

$$ \GL (n,\F ):=\set {A\in M\_{n\times n}(\F )\st \text {$A$ is invertible}}. $$

- [[Proposition 4.5]].
- - (1) Let $V$ be a vector space. Then $\GL (V)$ is a group under composition: $\psi \phi :=\psi \circ \phi$.
  - (2) If $V$ is an inner product space, then $\rO (V)$, resp. $\rU (V)$, is a subgroup of $\GL (V)$, when $\F =\R$, resp. $\C$.

- Proof.

  - (1) We check the axioms for a group, recalling that $\phi \in L(V)$ is an isomorphism if and only if it has an inverse.

    - • The multiplication is well-defined: that is, if $\psi ,\phi \in \GL (V)$ then so is $\psi \circ \phi$ which has inverse $\phi ^{-1}\circ \psi ^{-1}$.
    - • Composition of maps is always associative.
    - • $\id _V\in \GL (V)$ since $\id _V^{-1}=\id _V$ and is the identity element for composition.
    - • If $\phi \in \GL (V)$, then its inverse $\phi ^{-1}\in \GL (V)$ also since $(\phi ^{-1})^{-1}=\phi$.

  - (2) Denote $\rO (V)$ or $\rU (V)$, depending on $\F$, by $K$. Thus

    $\seteqnumber{0}{4.}{3}$

    $$ K=\set {\phi \in L(V)\st \phi ^{-1}=\phi ^{\*}}. $$

    Then

    - • $K$ is closed under composition: if $\psi ^{-1}=\psi ^{*}$ and $\phi ^{-1}=\phi ^{*}$ then, by [[Proposition 4.2]](1),

      $\seteqnumber{0}{4.}{3}$

      $$ (\psi \circ \phi )^{-1}=\phi ^{-1}\circ \psi ^{-1}=\phi ^{_}\circ \psi ^{_}=(\psi \circ \phi )^{\*} $$

      so that $\psi \circ \phi \in K$.

    - • $K$ is non-empty: [[Proposition 4.2]](4) tells us that $\id _V^{*}=\id _V=\id _V^{-1}$ so $\id _V\in K$.
    - • $K$ is closed under inversion: using [[Proposition 4.2]](3), we have $(\phi ^{-1})^{*}=(\phi ^{*})^{*}=\phi =(\phi ^{-1})^{-1}$.

  □

- Remark. The same argument shows that $\GL (n,\F )$ is a group under matrix multiplication with subgroup $\rO (n)$ or $\rU (n)$, depending on $\F$.

As an application of these ideas, let us characterise the distance-preserving transformations of a real inner product space.

- [[Theorem 4.6]] (Classification of rigid motions). Let $V$ be a _real_ inner product space. Recall that the _distance_ between $v,w\in V$ is $d(v,w):=\norm {v-w}$.

  A map $f:V\to V$ (not necessarily linear) is _distance-preserving_ or a _rigid motion_ if $d(f(v),f(w))=d(v,w)$, for all $v,w\in V$.

  $f$ is distance-preserving if and only if there is a $v_0\in V$ and $\phi \in L(V)$ a linear isometry such that

  $\seteqnumber{0}{4.}{3}$

  $$ \label {eq:15} f(v)=\phi (v)+v_0, $$

  for all $v\in V$.

- Proof. Suppose that $f$ is distance-preserving and that (4.4) held. Then we would have $f(0)=\phi (0)+v_0=0+v_0$. So, inspired by this, we define

  $\seteqnumber{0}{4.}{4}$

  $$ \begin{align*} v_0&:=f(0)\\\phi (v)&:=f(v)-v_0, \end{align*} $$ for all $v\in V$, and observe:

  $\seteqnumber{1}{4.5}{0}$

  $$ \begin{align*} \label {eq:16} \phi (0)&=v_0-v_0=0\\ \label {eq:18} \norm {\phi (v)-\phi (w)}&=\norm {v-w}. \end{align*} $$ We show that $\phi$ is a linear isometry in four steps:

  - 1. $\phi$ is norm-preserving: using (4.5), we have

    $\seteqnumber{0}{4.}{5}$

    $$ \norm {\phi (v)}=\norm {\phi (v)-\phi (0)}=\norm {v-0}=\norm {v}, $$

    for all $v\in V$.

  - 2. $\ip {\phi (v),\phi (w)}=\ip {v,w}$: we know from (4.5b) that $\norm {\phi (v)-\phi (w)}^2=\norm {v-w}^2$. Now expand this out, using the fact that the (real) inner product is symmetric, to get

    $\seteqnumber{0}{4.}{5}$

    $$ \norm {\phi (v)}^2-2\ip {\phi (v),\phi (w)}+\norm {\phi (w)}^2= \norm {v}^2-2\ip {v,w}+\norm {w}^2. $$

    But, from step 1, we know that $\norm {\phi (v)}^2=\norm {v}^2$ and $\norm {\phi (w)}^2=\norm {w}^2$ and the result follows.

  - 3. $\phi$ preserves addition: we compute:

    $\seteqnumber{0}{4.}{5}$

    $$ \begin{align*} \norm {\phi (v+w)-(\phi (v)+\phi (w))}^2&= \norm {\phi (v+w)}^2-2\ip {\phi (v+w),\phi (v)+\phi (w)}+\norm {\phi (v)+\phi (w)}^2 \\ \begin{split} &=\norm {\phi (v+w)}^2-2\ip {\phi (v+w),\phi (v)}-2\ip {\phi (v+w),\phi (w)}\\&\qquad + \norm {\phi (v)}^2+2\ip {\phi (v),\phi (w)}+\norm {\phi (w)}^2 \end {split} \\ &=\norm {v+w}^{2}-2\ip {v+w,v}-2\ip {v+w,w}+\norm {v}^{2}+2\ip {v,w}+\norm {w}^2\\ &=\norm {v+w}^2-2\norm {v+w}^2+\norm {v+w}^2=0. \end{align*} $$ Here we use steps 1 and 2 to reach the third line from the second. We now conclude from the definiteness of the inner product that $\phi (v+w)=\phi (v)+\phi (w)$, for all $v,w\in V$.

  - 4. $\phi$ preserves scalar multiplication: let $\lambda \in \R$ and compute:

    $\seteqnumber{0}{4.}{5}$

    $$ \begin{align*} \norm {\phi (\lambda v)-\lambda \phi (v)}^2 &=\norm {\phi (\lambda v)}^2-2\ip {\phi (\lambda v),\lambda \phi (v)}+\norm {\lambda \phi (v)}^{2}\\ &=\norm {\phi (\lambda v)}^2-2\lambda \ip {\phi (\lambda v),\phi (v)}+\lambda ^2\norm {\phi (v)}^2\\ &=\norm {\lambda v}^2-2\lambda \ip {\lambda v,v}+\lambda ^2\norm {v}^{2}\\ &=\lambda ^2\norm {v}^2-2\lambda ^2\norm {v}^2+\lambda ^2\norm {v}^2=0, \end{align*} $$ where, again, we use steps 1 and 2 for the third equality. Definiteness now yields $\phi (\lambda v)=\lambda \phi (v)$, for all $v\in V$, $\lambda \in \R$, so that $\phi$ is a linear isometry.

    Conversely, any $f$ of the form (4.4) is clearly distance-preserving.

  □

- Remark. Unitary groups play a fundamental role in theoretical physics. At the heart of the Standard Model that unifies electromagnetism with the sub-atomic strong and weak forces is the group $\rU (1)\times \rSU (2)\times \rSU (3)$ where $\rSU (n)=\set {A\in \rU (n)\st \det A=1}$ and I leave it to you to work out how one might make a Cartesian product of groups into a group.

4 This is the part where we use that $V$ is finite-dimensional.

5 Question 7 on sheet 6.
